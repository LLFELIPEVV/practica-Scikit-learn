# ğŸ“¦ IMPORTACIONES
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns  # Para grÃ¡ficos mÃ¡s profesionales

from collections import Counter
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score, recall_score, make_scorer

# ğŸ¨ CONFIGURACIÃ“N DE ESTILO PARA GRÃFICOS
sns.set_theme(style="whitegrid", palette="husl", font_scale=1.1)
plt.figure(figsize=(10, 6))  # TamaÃ±o por defecto para grÃ¡ficos

# ğŸ“‚ CARGA Y EXPLORACIÃ“N DE DATOS
# Cargamos solo las primeras 80,000 transacciones
df = pd.read_csv('creditcard.csv')[:80_000]
print("ğŸ” Primeras 3 transacciones:")
print(df.head(3))  # Mostramos muestra inicial de datos

# ğŸ¯ PREPARACIÃ“N DE DATOS PARA MODELADO
# Eliminamos columnas no relevantes
X = df.drop(columns=['Time', 'Amount', 'Class']).values
y = df['Class'].values  # Variable objetivo: 1 = fraude, 0 = transacciÃ³n normal
print(f"\nğŸ“ Dimensiones: X={X.shape} y={y.shape}")
print(f"âš ï¸ Casos de fraude detectados: {y.sum()}")

# ğŸ”„ MODELO DE REGRESIÃ“N LOGÃSTICA CON PESOS BALANCEADOS
print("\nğŸ”§ Entrenando modelo inicial...")
# Mayor peso a casos de fraude
mod = LogisticRegression(class_weight={0: 1, 1: 2}, max_iter=1000)
predicciones = mod.fit(X, y).predict(X)
print(f"ğŸ”® Predicciones de fraude iniciales: {predicciones.sum()}")

# ğŸ§ª OPTIMIZACIÃ“N DE HIPERPARÃMETROS CON BUSQUEDA EN REJILLA
print("\nâš™ï¸ Optimizando pesos de clases...")
grid = GridSearchCV(
    estimator=LogisticRegression(max_iter=1000),
    # Probamos 3 pesos diferentes
    param_grid={'class_weight': [{0: 1, 1: v} for v in range(1, 4)]},
    cv=4,  # ValidaciÃ³n cruzada con 4 divisiones
    n_jobs=-1  # Usar todos los nÃºcleos del procesador
)
grid.fit(X, y)
print("âœ… OptimizaciÃ³n completada!")

# ğŸ“ˆ MÃ‰TRICAS DE RENDIMIENTO
# Exactitud en detectar fraudes reales
presicion = precision_score(y, grid.predict(X))
# Capacidad de encontrar todos los fraudes
recall = recall_score(y, grid.predict(X))
print(f"\nğŸ“Š Resultados:")
print(
    f"â€¢ PrecisiÃ³n: {presicion:.2%} (Transacciones marcadas como fraude que realmente lo son)")
print(f"â€¢ Recall: {recall:.2%} (Fraudes reales detectados)")

# ğŸ•µï¸ MODELO DE DETECCIÃ“N DE ANOMALÃAS
print("\nğŸ” Entrenando modelo de detecciÃ³n de anomalÃ­as...")
mod = IsolationForest().fit(X)  # Modelo no supervisado
pre = np.where(mod.predict(X) == -1, 1, 0)  # Convertir predicciones a 0/1
print(f"ğŸ”® Posibles anomalÃ­as detectadas: {pre.sum()}")

# ğŸ¯ FUNCIONES PERSONALIZADAS PARA EVALUACIÃ“N


def outlier_precision(mod, X, y):
    """Calcula precisiÃ³n para detecciÃ³n de anomalÃ­as"""
    preds = mod.predict(X)
    return precision_score(y, np.where(preds == -1, 1, 0))


def outlier_recall(mod, X, y):
    """Calcula recall para detecciÃ³n de anomalÃ­as"""
    preds = mod.predict(X)
    return recall_score(y, np.where(preds == -1, 1, 0))


# ï¿½ OPTIMIZACIÃ“N DE MODELO DE ANOMALÃAS
print("\nâš™ï¸ Ajustando sensibilidad del detector...")
grid = GridSearchCV(
    estimator=IsolationForest(),
    param_grid={'contamination': np.linspace(
        0.001, 0.02, 10)},  # Rangos de contaminaciÃ³n
    scoring={'precision': outlier_precision, 'recall': outlier_recall},
    refit='precision',  # Priorizar precisiÃ³n al seleccionar mejor modelo
    cv=5,  # ValidaciÃ³n cruzada mÃ¡s estricta
    n_jobs=-1
)
grid.fit(X, y)
print("âœ… OptimizaciÃ³n completada!")

# ğŸ“Š VISUALIZACIÃ“N DE RESULTADOS (MEJORADA CON SEABORN)
new_df = pd.DataFrame(grid.cv_results_)

# GrÃ¡fico de lÃ­neas para tendencias
plt.figure(figsize=(12, 6))
sns.lineplot(data=new_df, x='param_contamination', y='mean_test_recall',
             label='Recall (DetecciÃ³n de fraudes)', linewidth=2.5, color='#2ecc71')
sns.lineplot(data=new_df, x='param_contamination', y='mean_test_precision',
             label='PrecisiÃ³n (Exactitud)', linewidth=2.5, color='#e74c3c')
plt.title(
    "RelaciÃ³n entre PrecisiÃ³n y Recall\n al variar la sensibilidad del detector", pad=20)
plt.xlabel("Nivel de ContaminaciÃ³n Ajustado", labelpad=12)
plt.ylabel("PuntuaciÃ³n", labelpad=12)
plt.legend()
plt.show()

# GrÃ¡fico de dispersiÃ³n para puntos individuales
plt.figure(figsize=(12, 6))
sns.scatterplot(data=new_df, x='param_contamination', y='mean_test_recall',
                label='Recall', s=100, color='#2ecc71', edgecolor='black')
sns.scatterplot(data=new_df, x='param_contamination', y='mean_test_precision',
                label='PrecisiÃ³n', s=100, color='#e74c3c', edgecolor='black')
plt.title("ComparaciÃ³n Directa de MÃ©tricas por ConfiguraciÃ³n", pad=20)
plt.xlabel("Nivel de ContaminaciÃ³n Ajustado", labelpad=12)
plt.ylabel("PuntuaciÃ³n", labelpad=12)
plt.legend()
plt.show()
